{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f90c5f",
   "metadata": {},
   "source": [
    "# Information Retrieval \n",
    "\n",
    "Information retrieval is defined as a completely automated procedure that answers to a user query by reviewing a group of documents and producing a sorted document list that ought to be relevant to the user's query criteria.\n",
    "\n",
    "The information retrieval process can be divided into four distinct phases: indexing,\n",
    "querying, comparison, and feedback.\n",
    "\n",
    "IR is widely used in various applications such as search engines, question answering systems, and recommendation systems. It has become increasingly important with the growth of digital information, which has made it challenging for users to find relevant information efficiently and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54f023",
   "metadata": {},
   "source": [
    "## Information Retrieval Search Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e85f03",
   "metadata": {},
   "source": [
    "- **Boolean model:** In the Boolean model, a query is represented as a Boolean expression of terms, and a document is either relevant or non-relevant to the query. This model is simple and efficient, but it can be too restrictive and may not account for partial matches or term frequency.\n",
    "\n",
    "- **Vector space model:** In the vector space model, a document is represented as a vector of term weights, and a query is represented as a vector of term weights as well. The similarity between the query vector and each document vector is computed using a similarity measure, such as cosine similarity. This model is flexible and can handle partial matches and term frequency, but it may suffer from the \"curse of dimensionality\" and may require normalization and tuning.\n",
    "\n",
    "- **Probabilistic model:** In the probabilistic model, a document is ranked based on the probability of relevance given the query, which is computed using Bayes' theorem. This model is more robust than the Boolean model and can handle partial matches and term frequency, but it may require tuning and may be sensitive to the choice of priors.\n",
    "\n",
    "- **Language model:** In the language model, a query is modeled as a language model, which is a probability distribution over terms, and a document is modeled as a language model as well. The relevance of a document to a query is measured using the likelihood ratio of the document language model under the query language model and the background language model. This model is effective in handling uncertainty and partial matches, but it may require tuning and may be sensitive to the choice of smoothing methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26a03e",
   "metadata": {},
   "source": [
    "### Boolean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8da0431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanRetrievalSystem:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vocab = set()\n",
    "        self.doc_freqs = []\n",
    "        self.doc_vectors = []\n",
    "        self.index()\n",
    "\n",
    "    def index(self):\n",
    "        # compute document frequencies and build vocabulary\n",
    "        self.doc_freqs = [set(doc.split()) for doc in self.documents]\n",
    "        self.vocab = set().union(*self.doc_freqs)\n",
    "\n",
    "    def search(self, query, k=10):\n",
    "        # preprocess query\n",
    "        #query_terms = set(query.split())\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        query_terms = [stemmer.stem(term.lower()) for term in query.split() if term.lower() not in stop_words]\n",
    "        \n",
    "        # compute document scores using boolean model\n",
    "        scores = []\n",
    "        for i, doc_freq in enumerate(self.doc_freqs):\n",
    "            # check if any query terms appear in document\n",
    "            if any(term in doc_freq for term in query_terms):\n",
    "                scores.append(i)\n",
    "        \n",
    "        # rank documents by score and return top k\n",
    "        return [self.documents[i] for i in scores[:k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae903776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A quick brown dog jumps over the lazy fox.', 'The lazy brown dog jumps over the quick fox.', 'The quick brown fox jumps over the lazy dog once more.', 'The dog is not so lazy anymore.', 'The brown dog and the black dog are chasing each other.']\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A quick brown dog jumps over the lazy fox.\",\n",
    "    \"The lazy brown dog jumps over the quick fox.\",\n",
    "    \"The quick brown fox jumps over the lazy dog once more.\",\n",
    "    \"The dog is not so lazy anymore.\",\n",
    "    \"The brown dog and the black dog are chasing each other.\",\n",
    "    \"I saw a blue car and a green car on my way to work.\",\n",
    "    \"The sky is blue but the water is clearer.\",\n",
    "    \"Blue is my favorite color, but green is a close second.\",\n",
    "    \"The sun is shining and the birds are singing.\"\n",
    "]\n",
    "\n",
    "br = BooleanRetrievalSystem(documents)\n",
    "results = br.search(\"lazy dog\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38af7a",
   "metadata": {},
   "source": [
    "### Vector space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "741b5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "class RetrievalSystem_VectorSpace:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vocab = set()\n",
    "        self.doc_freqs = []\n",
    "        self.doc_vectors = []\n",
    "        self.index()\n",
    "\n",
    "    def index(self):\n",
    "        # compute document frequencies and build vocabulary\n",
    "        self.doc_freqs = [Counter(doc.split()) for doc in self.documents]\n",
    "        self.vocab = set().union(*self.doc_freqs)\n",
    "        # compute document vectors\n",
    "        for doc_freq in self.doc_freqs:\n",
    "            doc_vector = [doc_freq.get(term, 0) for term in self.vocab]\n",
    "            self.doc_vectors.append(doc_vector)\n",
    "\n",
    "    def search(self, query, k=10):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        query_terms = [stemmer.stem(term.lower()) for term in query.split() if term.lower() not in stop_words]\n",
    "        scores = []\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            if any(term in self.doc_freqs[i] for term in query_terms):\n",
    "                query_vector = [Counter(query.split()).get(term, 0) for term in self.vocab]\n",
    "                cosine_sim = np.dot(doc_vector, query_vector) / (norm(doc_vector) * norm(query_vector)) if norm(doc_vector) and norm(query_vector) else 0\n",
    "                scores.append((i, cosine_sim))\n",
    "        ranked_docs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        return [self.documents[i] for i, _ in ranked_docs[:k] if _ > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b81d72f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The dog is not so lazy anymore.', 'A quick brown dog jumps over the lazy fox.', 'The lazy brown dog jumps over the quick fox.', 'The quick brown fox jumps over the lazy dog once more.', 'The brown dog and the black dog are chasing each other.']\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A quick brown dog jumps over the lazy fox.\",\n",
    "    \"The lazy brown dog jumps over the quick fox.\",\n",
    "    \"The quick brown fox jumps over the lazy dog once more.\",\n",
    "    \"The dog is not so lazy anymore.\",\n",
    "    \"The brown dog and the black dog are chasing each other.\",\n",
    "    \"I saw a blue car and a green car on my way to work.\",\n",
    "    \"The sky is blue but the water is clearer.\",\n",
    "    \"Blue is my favorite color, but green is a close second.\",\n",
    "    \"The sun is shining and the birds are singing.\"\n",
    "]\n",
    "\n",
    "rs = RetrievalSystem_VectorSpace(documents)\n",
    "results = rs.search(\" lazy dog \")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a23d5e7",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Pre-processing is a crucial step in information retrieval, as it helps to remove noise from the data and extract relevant features. Some pre-processing techniques include tokenization, stop-word removal, stemming, and normalization.\n",
    "\n",
    "## Document represenation\n",
    "\n",
    "Documents can be represented in different ways, such as bag-of-words models, TF-IDF models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5fa67",
   "metadata": {},
   "source": [
    "### Similarity (Scoring) Functions\n",
    "\n",
    "#### TF-IDF\n",
    "\n",
    "When we’re looking for document relevancy with a certain word, we want the word to be:\n",
    "\n",
    "- Common Locally: The word appears many times in the document\n",
    "- Rare Globally: The word doesn’t appear many times altogether in the corpus.\n",
    "\n",
    "Documents with a word that is common locally but rare globally are documents that are relevant for the given word. With TF-IDF, we can take into account both the Common Locally and Rare Globally factors of documents when calculating which are the most relevant.\n",
    "\n",
    "TF-IDF works like magic, it can calculate the most relevant documents just the way we want it to, but it has it's drawbacks.\n",
    "\n",
    "It doesn’t take document length into account: Let’s say that we have a 1,000 word document containing 1 appearance of the word \"soccer\" and with 10 appearances of the word \"soccer\". Which document do you think is more relevant to the word \"soccer\"? It should be the one with 10 words, because there is a greater chance that the document’s topic is about \"soccer\" compared to the 1,000 words one.\n",
    "\n",
    "The Term Frequency is not saturated: We know from the previous section that IDF will penalize common words. But what if there are some documents that naturally have so many common words? The Term Frequency’s value will be big. Because the Term Frequency of the TF-IDF function is not saturated, it will boost the irrelevant documents which contain many common words.\n",
    "Because of those shortcomings, people consider BM25 as the state-of-the-art similarity function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76cbc2",
   "metadata": {},
   "source": [
    "#### BM25 \n",
    "\n",
    "Okapi BM25 (Best Matching 25) is a ranking function used by search engines to evaluate the relevance of documents to a given search query. It is a probabilistic model that calculates the score of a document based on the frequency of query terms within the document, as well as their frequency within the entire collection of documents.\n",
    "\n",
    "BM25 takes into account the inverse document frequency (IDF) of query terms, as well as the document length and term frequency (TF) of each term within a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285ad0f",
   "metadata": {},
   "source": [
    "![alt text](bm25-formula.png \"bm25 equation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4cc66",
   "metadata": {},
   "source": [
    "We can control how much the function penalizes longer documents by changing the b parameter. If we use a large value for b, then the function will penalize the longer document’s score more.\n",
    "\n",
    "the parameter k1 will determine how saturated the Term Frequency is. The lower the value of k1 is, the more saturated the Term Frequency is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95edd1",
   "metadata": {},
   "source": [
    "#### BM25 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38a60629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "docs[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57010f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\salma\\anaconda3\\lib\\site-packages (from rank-bm25) (1.23.5)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63030ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "tokenized_corpus = [doc.lower().split(\" \") for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "810e387f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah right sorta like the indian subcontient eh'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "corpus = [doc.translate(str.maketrans('', '', string.punctuation)).replace('\\n',\"\").lower() for doc in corpus]\n",
    "\n",
    "corpus[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dd8a5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am fairly sure that she could obtain citizenship by making anapplication for it it might require immigration to germany buti am almost certain that once applied for citizenship is inevitablein this casemore interesting only for your propaganda purposes i have said severaltimes now that i dont consider iran particularly exemplary as a goodislamic state we might talk about the rights of people in capitalistsecular third world countries to give other examples of the lack ofrights in third world countries broadly say for example centralamerican secular capitalist countries whose govts the us supportsbut who amnesty international has pointed out are human rights vacua',\n",
       " '   analog sf magazine did an article on a similar subject quite a fewyears ago  the question was if an alien spacecraft landed inwashington dc what was the proper organization to deal with it thestate department alien ambassadors the defense department alieninvaders the immigration and naturalization service illegal aliensthe department of the interior new nonhuman species etc  it wasvery much a question of our perception of the aliens not of anythingintrinsic in their nature  the bibliography for the article cited aphilosophical paper the name and author of which i sadly forget ibelieve the author was italian on what constitutes a legal andor moralperson ie a being entitled to the rights normally accorded to aperson  the paper was quite interesting as i recall   i think youd have to be very careful here if the answer is yes  thehuman track record on helping those poor underpriveleged cultures doesunderpriveleged mean not having enough priveleges is terrible  theusual result is the destruction or radical reorganization of theculture  this may not always be wrong but thats the way to bet',\n",
       " 'does this imply the german tone dialing is compatible with the american one  i know at least the british system is not  it is supposedly close enough though that an american phone will work  but my modem americanhas a special setting for british standardsmichael',\n",
       " 'the problem if  transffering us government files about yigal arensand some other similar persons does or does not violate a federalor a local american law seemed to belong to some local american lawforum  not to this forumthe readers of this forum seemed to be more interested in the contentsof those filesso it will be nice if yigal will tell us1 why do american authorities consider yigal arens to be dangerous2 why does the adl have an interest in that person 3 if one does trust either the us government or the adl what an   additional information should he send them ']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"american immigration\"\n",
    "tokenized_query = query.lower().split(\" \")\n",
    "bm25.get_top_n(tokenized_query, corpus, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28897511",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.simplilearn.com/tutorials/machine-learning-tutorial/information-\n",
    "- https://www.cs.waikato.ac.nz/~ihw/papers/00-SJC-JL-IHW-Applicationml.pdf\n",
    "- https://www.geeksforgeeks.org/what-is-information-retrieval/\n",
    "- https://ris.utwente.nl/ws/portalfiles/portal/5588097/IRModelsTutorial-draft.pdf\n",
    "- https://towardsdatascience.com/understanding-term-based-retrieval-methods-in-information-retrieval-2be5eb3dde9f\n",
    "- https://www.infoq.com/articles/similarity-scoring-elasticsearch/\n",
    "- https://towardsdatascience.com/getting-started-with-elasticsearch-in-python-c3598e718380\n",
    "- https://iamgeekydude.com/2022/11/21/how-to-build-a-search-engine-using-bm25-ranking/\n",
    "- https://eudl.eu/pdf/10.4108/eetiot.v8i3.2276"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
